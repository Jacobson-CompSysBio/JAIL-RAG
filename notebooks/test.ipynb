{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import preprocess as pp\n",
    "# from utils.llm import llm\n",
    "from utils.graph_llm import GraphLLM\n",
    "from utils.llm import LLM\n",
    "from utils.multiplex import Multiplex\n",
    "from utils.textualize import *\n",
    "from utils.GetFileNames import GetFileNames\n",
    "from utils.GetLowestGPU import GetLowestGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load Networks as `Multiplex` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist_name = '../data/DREAM4_gold_standards/flist.tsv'\n",
    "mp = Multiplex(flist_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Textualize Graphs (Ken's Code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 is associated with G2 in coexpression-heart\n",
      "G1 is associated with G3 in coexpression-heart\n",
      "G1 is associated with G4 in coexpression-heart\n",
      "G1 is associated with G5 in coexpression-heart\n",
      "G1 is associated with G6 in coexpression-heart\n",
      "G1 is associated with G7 in coexpression-heart\n",
      "G1 is associated with G8 in coexpression-heart\n",
      "G1 is associated with G9 in coexpression-heart\n",
      "G1 is associated with G10 in coexpression-heart\n",
      "G2 is associated with G6 in coexpression-heart\n"
     ]
    }
   ],
   "source": [
    "textualize = load_textualizer['edges']\n",
    "graph_text = textualize(mp)\n",
    "\n",
    "# view first 10 items\n",
    "for i in range(10):\n",
    "    print(graph_text[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Make Dataloader\n",
    "* dataloader returns dict with keys `[\"ids\"]`, `[\"desc\"]`,`[\"question\"]`,`[\"label\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Load In Encoder + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLaMA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19c2fa5f7d84d9a9d9ab02a1525fe2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing LLaMA...\n",
      "Finished loading LLaMA...\n",
      "Loading LLaMA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751962c82ea34f408eccadda515e8ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing LLaMA!\n",
      "Finished loading LLaMA!\n"
     ]
    }
   ],
   "source": [
    "vanilla_llm = LLM(max_text_len=512,\n",
    "                  max_max_new_tokens=32,\n",
    "                  max_memory=[80, 80],\n",
    "                  llm_model_path='meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "                  llm_frozen='True',\n",
    "                  revision=\"main\") # need to add args\n",
    "\n",
    "graph_llm = GraphLLM(max_text_len=512,\n",
    "                     max_max_new_tokens=32,\n",
    "                     max_memory=[80, 80],\n",
    "                     llm_model_path='meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "                     llm_frozen='True',\n",
    "                     revision=\"main\") # args are defaulted in the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Perform Initial Untrained Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get args\n",
    "arg1 = [\"Cannabis should be legal.\", \n",
    "        \"Women should not be in combat.\"]\n",
    "arg2 = [\"It's not a bad thing to make marijuana more available.\", \n",
    "        \"Women and men have the same rights.\"]\n",
    "label = [\"support\", \n",
    "         \"counter\"]\n",
    "graph = [\"(cannabis; synonym of; marijuana)(legal; causes; more available)(marijuana; capable of; good thing)(good thing; desires; legal)\", \n",
    "         \"(women and men; is a; citizens)(citizens; causes; have same rights)(have same rights; causes; women)(women; capable of; help the country)(help the country; desires; be in combat)\"]\n",
    "\n",
    "# make a fake dataset dict\n",
    "expla_graph = {\n",
    "    'id': [1, 2],\n",
    "    'arg1': arg1,\n",
    "    'arg2': arg2,\n",
    "    'label': label,\n",
    "    'graph': graph,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplaGraphsDataset(Dataset):\n",
    "    def __init__(self, expla_graph=expla_graph):\n",
    "        super().__init__()\n",
    "\n",
    "        self.text = expla_graph\n",
    "        self.prompt = 'Question: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of \\'support\\' or \\'counter\\'.\\n\\nAnswer:'\n",
    "        self.graph_type = 'Explanation Graph'\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the len of the dataset.\"\"\"\n",
    "        return len(self.text['id'])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        question = f'Argument 1: {self.text[\"arg1\"][index]}\\nArgument 2: {self.text[\"arg2\"][index]}\\n{self.prompt}'\n",
    "        desc = self.text[\"graph\"][index]\n",
    "        return {\n",
    "            'id': index,\n",
    "            'label': self.text['label'][index],\n",
    "            'desc': desc,\n",
    "            'question': question,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ExplaGraphsDataset(expla_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': tensor([0]),\n",
       " 'pred': ['support[/INST]\\n\\nIn this example, the two arguments support each other. Argument 1 states that cannabis should be legal, and argument 2 states that making'],\n",
       " 'label': ['support'],\n",
       " 'question': [\"Argument 1: Cannabis should be legal.\\nArgument 2: It's not a bad thing to make marijuana more available.\\nQuestion: Do argument 1 and argument 2 support or counter each other? Answer in one word in the form of 'support' or 'counter'.\\n\\nAnswer:\"],\n",
       " 'desc': ['(cannabis; synonym of; marijuana)(legal; causes; more available)(marijuana; capable of; good thing)(good thing; desires; legal)']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_llm.inference(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Evaluate After Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
