{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from importlib import reload\n",
    "from torch_scatter import scatter\n",
    "from transformers import pipeline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import preprocess as pp\n",
    "from utils.evaluate import eval_funcs, normalize\n",
    "from utils.collate import collate_fn \n",
    "from utils.ckpt import _reload_best_model\n",
    "from utils.graph_llm import GraphLLM\n",
    "from utils.llm import LLM\n",
    "from utils.multiplex import Multiplex\n",
    "from utils.textualize import *\n",
    "from utils.bio_graphs import BiologicalDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "# base_path = '../data/DREAM4_gold_standards/'\n",
    "\n",
    "# c_node_id_data = BiologicalDataset(base_path + 'connections_node_id')\n",
    "# c_node_label_data = BiologicalDataset(base_path + 'connections_node_label')\n",
    "# sp_node_id_data = BiologicalDataset(base_path + 'shortest_path_node_id')\n",
    "# sp_node_label_data = BiologicalDataset(base_path + 'shortest_path_node_label')\n",
    "# get dataset\n",
    "data_path = '../data/DREAM4_gold_standards/connections_node_label'\n",
    "dataset = BiologicalDataset(data_path)\n",
    "idx_split = dataset.get_idx_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DGX01/Personal/krusepi/codebase/projects/llms/JAIL-RAG/notebooks/../utils/bio_graphs.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  graph = torch.load(f'{self.path}/graphs/{index}.pt')\n"
     ]
    }
   ],
   "source": [
    "# split datasets on idx\n",
    "train_dataset = [dataset[i] for i in idx_split[\"train\"]]\n",
    "val_dataset = [dataset[i] for i in idx_split[\"val\"]]\n",
    "test_dataset = [dataset[i] for i in idx_split[\"test\"]]\n",
    "\n",
    "# options\n",
    "batch_size = 1\n",
    "\n",
    "# make dataloaders\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          drop_last=True,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          drop_last=True,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                          batch_size=batch_size,\n",
    "                          drop_last=True,\n",
    "                          pin_memory=True,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLaMA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0694182f8244efda9b1cefb38c829b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing LLaMA...\n",
      "Finished loading LLaMA...\n"
     ]
    }
   ],
   "source": [
    "vanilla_llm = LLM(max_text_len=512,\n",
    "                  max_max_new_tokens=32,\n",
    "                  max_memory=[80, 80],\n",
    "                  llm_model_path='meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "                  llm_frozen='True',\n",
    "                  revision=\"main\") # need toadd args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLaMA...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94254fd81e294077b5597567071626f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing LLaMA!\n",
      "Finished loading LLaMA!\n"
     ]
    }
   ],
   "source": [
    "# base model\n",
    "base_graph_llm = GraphLLM(max_text_len=512,\n",
    "                     max_max_new_tokens=32,\n",
    "                     max_memory=[80, 80],\n",
    "                     llm_model_path='meta-llama/Meta-Llama-3-8B-Instruct',\n",
    "                     llm_frozen='True',\n",
    "                     revision=\"main\") # args are defaulted in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from ../checkpoints/test_run/epoch_5_best.pth.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/DGX01/Personal/krusepi/codebase/projects/llms/JAIL-RAG/notebooks/../utils/ckpt.py:64: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "# path\n",
    "path = '../checkpoints/test_run/epoch_5_best.pth'\n",
    "\n",
    "# load model\n",
    "trained_graph_llm = _reload_best_model(base_graph_llm, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Node Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6bd48ec3b14adbb4862dac2f1ea5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes there is edge between nodes g7 and g4 edge is directed from g7 to g4 indicating that g7 is associated with\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between g10 and g3 as indicated by association g3 is associated with g10endoftext\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between nodes g1 and g5 edge is associated with string g1 is associated with g5 this edge\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between nodes g1 and g10 edge is result of associations between nodes which can be seen in graph\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes there is edge between nodes g2 and g8 edge is formed by association g2 is associated with g8\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between g8 and g10 edge is associated with edge g3 is associated with g10 and edge\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes there is edge between nodes g4 and g9 this edge is associated with string g4 is associated with g10 which implies\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes there is edge between g9 and g3 as mentioned in last line of text g3 is associated with g10\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "according to given graph data there is no edge between nodes g5 and g9 graph only contains edges between nodes g1 and g2\n",
      "no \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between nodes g1 and g8 edge is formed by association g2 is associated with g8 this association\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes there is edge between nodes g1 and g5 edge is labeled as g1 is associated with g5endoft\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes according to given data there is edge between g3 and g8 because g2 is associated with g8 and g3 is associated with\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes there is edge between nodes g10 and g4 edge is formed by association g3 is associated with g4 and\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "no there is no edge between nodes g9 and g5 in fact there is no edge between any of nodes g5 g6\n",
      "no \n",
      "\n",
      "Correct!\n",
      "\n",
      "according to given graph there is no edge between nodes g5 and g4 graph only shows edges between nodes g1 and g2 g\n",
      "no \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between nodes g4 and g2 edge is inferred from text as follows g1 is associated with g2\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes there is edge between nodes g4 and g3 edge is directed from g4 to g3 edge is labeled as g\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "there are no edges between nodes g6 and g3 there are only edges between nodes g6 and g8 and g3 and g4 to\n",
      "no \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between nodes g8 and g7 this is because there is edge between nodes g3 and g7 and g8\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes there is edge between nodes g4 and g7 edge is directed from g4 to g7 indicating that g4 is associated with\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between nodes g2 and g6 edge is directed from g2 to g6 this can be inferred from edge\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between nodes g3 and g1 edge is formed by association g3 is associated with g1 edge\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "no there is no edge between nodes g8 and g9 graph only contains edges between nodes g1 and g2 g1 and g3\n",
      "no \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between nodes g10 and g2 edge is formed by association g2 is associated with g8 and since\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes there is edge between nodes g3 and g7 edge is labeled as g3 is associated with g7endoft\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "there are 2 edges between g6 and g2 first edge is from line g2 is associated with g6 second edge is\n",
      "yes \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes there is edge between nodes g5 and g1 edge is labeled g1 is associated with g5endoftext\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between nodes g1 and g4 edge is present in graph because there is association between g1 and g4\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between nodes g6 and g8 edge is inferred from graph data where g6 is associated with g8\n",
      "yes \n",
      "\n",
      "Correct!\n",
      "\n",
      "yes there is edge between g8 and g3 as indicated by line g2 is associated with g8 and g3 is\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "yes there is edge between nodes g5 and g3 edge is present in graph because g5 is associated with g1 and g\n",
      "no \n",
      "\n",
      "Incorrect :(\n",
      "\n",
      "Accuracy: 58.06% | 18/31\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "verbose = True\n",
    "model = trained_graph_llm\n",
    "loader = train_loader\n",
    "\n",
    "# set to eval\n",
    "model.model.generation_config.pad_token_id = model.tokenizer.pad_token_id\n",
    "model.eval()\n",
    "\n",
    "n_correct = 0\n",
    "# loop through dataloader\n",
    "for batch in tqdm(loader):\n",
    "    out = model.inference(batch)\n",
    "\n",
    "    pred = out['pred']\n",
    "    actual = out['label']\n",
    "\n",
    "    # test accuracy\n",
    "    for p, a in zip(pred, actual):\n",
    "        p = normalize(p)\n",
    "        a = normalize(a) + ' '\n",
    "        if verbose:\n",
    "            print(p)\n",
    "            print(a)\n",
    "            print()\n",
    "        if a in p:\n",
    "            n_correct += 1\n",
    "            if verbose:\n",
    "                print(\"Correct!\")\n",
    "                print()\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"Incorrect :(\")\n",
    "                print()\n",
    "\n",
    "acc = n_correct / len(loader)\n",
    "print(f\"Accuracy: {acc:.2%} | {n_correct}/{len(loader)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
